# 6XGboost_MLProject

ğŸ§  Wholesale Customers Segmentation using XGBoost
ğŸ“Œ Project Overview

This project focuses on classifying Wholesale Customers into Horeca (Hotel/Restaurant/CafÃ©) or Retail categories using the XGBoost algorithm.
The model analyzes customersâ€™ purchasing behavior to understand which features (like Grocery, Milk, Fresh, etc.) influence customer segmentation.

ğŸ¯ Objective

To build an accurate and interpretable machine learning model using XGBoost that predicts the customer channel type based on purchasing data.

âš™ï¸ Workflow Summary
1. Importing Libraries

Essential Python libraries were imported:

pandas, numpy â†’ Data manipulation

matplotlib, seaborn â†’ Data visualization (EDA)

sklearn â†’ Data splitting and evaluation metrics

xgboost â†’ Main ML algorithm

2. Loading the Dataset

Dataset: Wholesale customers data.csv
It includes customer purchase data for various product categories (Milk, Grocery, Detergents, etc.) and their Channel (target label).

3. Exploratory Data Analysis (EDA)

Performed to:

Understand feature distributions

Check missing values

Detect outliers

Visualize relationships between features

EDA ensures data quality and helps identify which features are likely to be important.

4. Feature and Target Split

Features (X): All columns except Channel

Target (y): Channel (customer type)

This separation allows the model to learn the mapping X â†’ y.

5. Trainâ€“Test Split

Data is split into:

Training Set (80%) â†’ Used to train the model

Testing Set (20%) â†’ Used to evaluate model performance

This ensures that the model generalizes well on unseen data.

6. Model Training with XGBoost

XGBoost is an ensemble-based gradient boosting algorithm.

It trains multiple decision trees sequentially â€” each new tree corrects errors made by previous ones.

Regularization (L1 & L2) helps prevent overfitting.

Key parameters used:

max_depth = 4
alpha = 10
learning_rate = 1.0
colsample_bytree = 0.3

7. Baseline Model Evaluation

Model was evaluated using:

accuracy_score(y_test, y_pred)


Baseline Accuracy: ~91.67%

8. k-Fold Cross Validation

To validate model consistency, 3-fold cross-validation was applied using:

xgboost.cv()


This provided more reliable metrics like AUC, ensuring the model is stable across data splits.

9. Feature Importance

Feature importance plot was generated to identify which variables most influenced predictions.

Top influential features:

Grocery

Detergents_Paper

Milk

10. Final Evaluation

Final model performance was assessed using:

Accuracy Score

AUC Score

Cross-validation metrics

The model achieved high accuracy and strong generalization on unseen data.

ğŸ“ˆ Results Summary
Metric	Value
Accuracy	91.67%
AUC (Cross-Validation)	High (Consistent Performance)
Important Features	Grocery, Milk, Detergents_Paper
ğŸ§© Key Learnings

XGBoost provides speed, accuracy, and interpretability.

Regularization (L1 & L2) helps control overfitting.

Cross-validation ensures robust performance evaluation.

Understanding feature importance improves business insight.

project-root/
  data/
    Wholesale customers data.csv
  notebooks/
    XGBoost_Model.ipynb
  src/
    model.py
  results/
    feature_importance.png
  README.md
  requirements.txt



ğŸ§° Technologies Used

Python 3.x

XGBoost

NumPy / Pandas

Matplotlib / Seaborn

Scikit-learn

ğŸš€ Future Enhancements

Apply GridSearchCV for deeper hyperparameter tuning

Try other models (Random Forest, LightGBM) for comparison

Deploy model using Streamlit or Flask
